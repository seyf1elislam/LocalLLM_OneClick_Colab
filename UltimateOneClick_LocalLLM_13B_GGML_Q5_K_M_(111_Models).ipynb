{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UltimateOneClick_13BLLM_GGML_Q5_K_M (111 Models) with just 1 click\n",
        "## Hello there!\n",
        "* Here are 111 models (13B LLM ggml Q5_K_M), including the latest such as WizarldLLM1.2, LLAMA 2 chat...\n",
        "* Just choose a model, then run the cells.\n",
        "* More Quantized models will be added when they are released, as well as some GPTQ versions; simply check the repo again later.\n",
        "\n",
        "\n",
        "[$\\color{#19ABEA}{\\text{Click her to Check out what's new on Github.❤️}}$](https://github.com/seyf1elislam/LocalLLM_UltimateOneClick_Colab)\n",
        "\n"
      ],
      "metadata": {
        "id": "oHxh9ciAUzpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RkaKaQ1NUdQD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b2f895c-fbc2-4cd8-dc05-87d697e47a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "#@title $\\color{#19ABEA}{\\text{Prepare Container and install Requirments}}$ { display-mode: \"form\" }\n",
        "#@markdown # $\\color{#19ABEA}{\\text{Run This once to install Requirments}}$\n",
        "%cd /content\n",
        "!apt-get -y install -qq aria2\n",
        "!git clone -b V20230720 https://github.com/Troyanovsky/text-generation-webui\n",
        "%cd /content/text-generation-webui\n",
        "!pip install -r requirements.txt\n",
        "!pip install -U gradio==3.32.0\n",
        "!pip install git+https://github.com/mnt4/flask-cloudflared\n",
        "# !pip install flask_cloudflared #--force-reinstall\n",
        "!pip uninstall -y llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir\n",
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # $\\color{#19ABEA}{\\text{Choose and download the model}}$ { display-mode: \"form\" }\n",
        "def download_url(name,filename):\n",
        "  return f\"https://huggingface.co/{name}/resolve/main/{filename}\"\n",
        "NametoFile={ \"TheBloke/13B-BlueMethod-GGML\":\"13b-bluemethod.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/13B-Chimera-GGML\":\"13b-chimera.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/13B-HyperMantis-GGML\":\"13B-HyperMantis.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/13B-Legerdemain-L2-GGML\":\"13b-legerdemain-l2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/13B-Ouroboros-GGML\":\"13b-ouroboros.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Airochronos-L2-13B-GGML\":\"airochronos-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Airolima-Chronos-Grad-L2-13B-GGML\":\"airolima-chronos-grad-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/AlpacaCielo-13B-GGML\":\"alpacacielo-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Baize-v2-13B-SuperHOT-8K-GGML\":\"baize-13b-v2-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/BigTranslate-13B-GGML\":\"bigtrans-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/CAMEL-13B-Combined-Data-GGML\":\"camel-13b-combined.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/CAMEL-13B-Combined-Data-SuperHOT-8K-GGML\":\"camel-13b-combined-data-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/CAMEL-13B-Role-Playing-Data-GGML\":\"camel-13b-roleplay.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/CAMEL-13B-Role-Playing-Data-SuperHOT-8K-GGML\":\"camel-13b-role-playing-data-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Camel-Platypus2-13B-GGML\":\"camel-platypus2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronoboros-Grad-L2-13B-GGML\":\"chronoboros-grad-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronohermes-Grad-L2-13B-GGML\":\"chronohermes-grad-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronolima-Airo-Grad-L2-13B-GGML\":\"chronolima-airo-grad-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronos-13B-SuperHOT-8K-GGML\":\"chronos-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronos-13B-v2-GGML\":\"chronos-13b-v2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronos-Beluga-v2-13B-GGML\":\"chronos-beluga-v2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Chronos-Hermes-13B-v2-GGML\":\"chronos-hermes-13b-v2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGML\":\"codeup-llama-2-13b-chat-hf.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Dolphin-Llama-13B-GGML\":\"dolphin-llama-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Firefly-Llama2-13B-v1.2-GGML\":\"firefly-llama2-13b-v1.2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/GPT4All-13B-Snoozy-SuperHOT-8K-GGML\":\"gpt4all-snoozy-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/GPT4All-13B-snoozy-GGML\":\"GPT4All-13B-snoozy.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Hermes-LLongMA-2-13B-8K-GGML\":\"hermes-llongma-2-13b-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Huginn-13B-GGML\":\"huggin-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Karen_theEditor_13B-GGML\":\"Karen-The-Editor.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Kimiko-13B-GGML\":\"kimiko-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Koala-13B-SuperHOT-8K-GGML\":\"koala-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/LLaMa-13B-GGML\":\"llama-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Llama-2-13B-GGML\":\"llama-2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Llama-2-13B-chat-GGML\":\"llama-2-13b-chat.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/LongChat-13B-GGML\":\"longchat-13b-16k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GGML\":\"manticore-13b-chat-pyg-guanaco-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Manticore-13B-Chat-Pyg-SuperHOT-8K-GGML\":\"manticore-13b-chat-pyg-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Manticore-13B-GGML\":\"Manticore-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Manticore-13B-SuperHOT-8K-GGML\":\"manticore-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Minotaur-13B-fixed-SuperHOT-8K-GGML\":\"minotaur-13b-fixed-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/MythoBoros-13B-GGML\":\"mythoboros-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/MythoLogic-13B-GGML\":\"mythologic-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/MythoLogic-L2-13B-GGML\":\"mythologic-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/MythoMax-L2-13B-GGML\":\"mythomax-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/MythoMix-L2-13B-GGML\":\"mythomix-l2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Nous-Hermes-13B-GGML\":\"nous-hermes-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGML\":\"openassistant-llama2-13b-orca-8k-3319.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/OpenAssistant-Llama2-13B-Orca-v2-8K-3166-GGML\":\"openassistant-llama2-13b-orca-v2-8k-3166.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/OpenOrca-Preview1-13B-GGML\":\"openorca-preview1-200k-llama-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/OpenOrcaxOpenChat-Preview2-13B-GGML\":\"openorcaxopenchat-preview2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Platypus2-13B-GGML\":\"platypus2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Pygmalion-13B-SuperHOT-8K-GGML\":\"pygmalion-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Redmond-Puffin-13B-GGML\":\"redmond-puffin-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Robin-13B-v2-SuperHOT-8K-GGML\":\"robin-13b-v2-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Samantha-13B-SuperHOT-8K-GGML\":\"samantha-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Selfee-13B-GGML\":\"selfee-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Selfee-13B-GGML-DOI\":\"selfee-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Stable-Platypus2-13B-GGML\":\"stable-platypus2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/StableBeluga-13B-GGML\":\"stablebeluga-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Vicuna-13B-CoT-GGML\":\"vicuna-13b-cot.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Vicuna-13B-v1.3-German-GGML\":\"vicuna-13b-v1.3-german.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Vigogne-2-13B-Instruct-GGML\":\"vigogne-2-13b-instruct.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Vigogne-Instruct-13B-GGML\":\"Vigogne-Instruct-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Wizard-Vicuna-13B-Uncensored-GGML\":\"Wizard-Vicuna-13B-Uncensored.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GGML\":\"wizard-vicuna-13b-uncensored-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGML\":\"wizardlm-1.0-uncensored-llama2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardLM-13B-Uncensored-GGML\":\"wizardLM-13B-Uncensored.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardLM-13B-V1-0-Uncensored-SuperHOT-8K-GGML\":\"wizardlm-13b-v1.0-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardLM-13B-V1.0-Uncensored-GGML\":\"wizardlm-13b-v1.0-uncensored.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardLM-13B-V1.1-GGML\":\"wizardlm-13b-v1.1.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardLM-13B-V1.2-GGML\":\"wizardlm-13b-v1.2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/WizardMath-13B-V1.0-GGML\":\"wizardmath-13b-v1.0.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-13B-1.1-GGML\":\"airoboros-13b-1.1.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-13B-gpt4-1.2-GGML\":\"airoboros-13b-gpt4-1.2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-13B-gpt4-1.3-GGML\":\"airoboros-13b-gpt4-1.3.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-13B-gpt4-1.4-GGML\":\"airoboros-13b-gpt4-1.4.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-13b-gpt4-GGML\":\"airoboros-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-l2-13B-gpt4-1.4.1-GGML\":\"airoboros-l2-13b-gpt4-1.4.1.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-l2-13b-gpt4-2.0-GGML\":\"airoboros-l2-13b-gpt4-2.0.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/airoboros-l2-13b-gpt4-m2.0-GGML\":\"airoboros-l2-13b-gpt4-m2.0.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/based-13b-GGML\":\"based-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/chronos-13B-GGML\":\"chronos-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/chronos-wizardlm-uc-scot-st-13B-GGML\":\"chronos-wizardlm-uc-scot-st-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/gpt4-x-alpaca-13B-GGML\":\"gpt4-x-alpaca-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/gpt4-x-vicuna-13B-GGML\":\"gpt4-x-vicuna-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/guanaco-13B-GGML\":\"guanaco-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/h2ogpt-4096-llama2-13B-GGML\":\"h2ogpt-4096-llama2-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/h2ogpt-4096-llama2-13B-chat-GGML\":\"h2ogpt-4096-llama2-13b-chat.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/koala-13B-GGML\":\"koala-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/llama-2-13B-German-Assistant-v2-GGML\":\"llama-2-13b-german-assistant-v2.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/llama-2-13B-Guanaco-QLoRA-GGML\":\"llama-2-13b-guanaco-qlora.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/manticore-13b-chat-pyg-GGML\":\"Manticore-13B-Chat-Pyg.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/minotaur-13B-GGML\":\"minotaur-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/minotaur-13B-fixed-GGML\":\"minotaur-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/open-llama-13b-open-instruct-GGML\":\"open-llama-13b-open-instruct.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/orca_mini_13B-GGML\":\"orca-mini-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/orca_mini_v2_13b-GGML\":\"orca_mini_v2_13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/orca_mini_v3_13B-GGML\":\"orca_mini_v3_13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/robin-13B-v2-GGML\":\"robin-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/samantha-1.1-llama-13B-GGML\":\"samantha-1.1-llama-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/samantha-13B-GGML\":\"samantha-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/stable-vicuna-13B-GGML\":\"stable-vicuna-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/tulu-13B-GGML\":\"tulu-13b.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/vicuna-13B-v1.5-16K-GGML\":\"vicuna-13b-v1.5-16k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/vicuna-13B-v1.5-GGML\":\"vicuna-13b-v1.5.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/vicuna-13b-1.1-GGML\":\"vicuna-13b-1.1.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/vicuna-13b-v1.3.0-GGML\":\"vicuna-13b-v1.3.0.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/wizard-vicuna-13B-GGML\":\"wizard-vicuna-13B.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/wizard-vicuna-13B-SuperHOT-8K-GGML\":\"wizard-vicuna-13b-superhot-8k.ggmlv3.q5_K_M.bin\",\n",
        " \"TheBloke/wizardLM-13B-1.0-GGML\":\"WizardLM-13B-1.0.ggmlv3.q5_K_M.bin\"}\n",
        "#@markdown # $\\color{#19ABEA}{\\text{Choose model :}}$\n",
        "\n",
        "choosed_model_name = \"TheBloke/Manticore-13B-Chat-Pyg-SuperHOT-8K-GGML\" #@param ['TheBloke/13B-BlueMethod-GGML','TheBloke/13B-Chimera-GGML','TheBloke/13B-HyperMantis-GGML','TheBloke/13B-Legerdemain-L2-GGML','TheBloke/13B-Ouroboros-GGML','TheBloke/Airochronos-L2-13B-GGML','TheBloke/Airolima-Chronos-Grad-L2-13B-GGML','TheBloke/AlpacaCielo-13B-GGML','TheBloke/Baize-v2-13B-SuperHOT-8K-GGML','TheBloke/BigTranslate-13B-GGML','TheBloke/CAMEL-13B-Combined-Data-GGML','TheBloke/CAMEL-13B-Combined-Data-SuperHOT-8K-GGML','TheBloke/CAMEL-13B-Role-Playing-Data-GGML','TheBloke/CAMEL-13B-Role-Playing-Data-SuperHOT-8K-GGML','TheBloke/Camel-Platypus2-13B-GGML','TheBloke/Chronoboros-Grad-L2-13B-GGML','TheBloke/Chronohermes-Grad-L2-13B-GGML','TheBloke/Chronolima-Airo-Grad-L2-13B-GGML','TheBloke/Chronos-13B-SuperHOT-8K-GGML','TheBloke/Chronos-13B-v2-GGML','TheBloke/Chronos-Beluga-v2-13B-GGML','TheBloke/Chronos-Hermes-13B-v2-GGML','TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGML','TheBloke/Dolphin-Llama-13B-GGML','TheBloke/Firefly-Llama2-13B-v1.2-GGML','TheBloke/GPT4All-13B-Snoozy-SuperHOT-8K-GGML','TheBloke/GPT4All-13B-snoozy-GGML','TheBloke/Hermes-LLongMA-2-13B-8K-GGML','TheBloke/Huginn-13B-GGML','TheBloke/Karen_theEditor_13B-GGML','TheBloke/Kimiko-13B-GGML','TheBloke/Koala-13B-SuperHOT-8K-GGML','TheBloke/LLaMa-13B-GGML','TheBloke/Llama-2-13B-GGML','TheBloke/Llama-2-13B-chat-GGML','TheBloke/LongChat-13B-GGML','TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GGML','TheBloke/Manticore-13B-Chat-Pyg-SuperHOT-8K-GGML','TheBloke/Manticore-13B-GGML','TheBloke/Manticore-13B-SuperHOT-8K-GGML','TheBloke/Minotaur-13B-fixed-SuperHOT-8K-GGML','TheBloke/MythoBoros-13B-GGML','TheBloke/MythoLogic-13B-GGML','TheBloke/MythoLogic-L2-13B-GGML','TheBloke/MythoMax-L2-13B-GGML','TheBloke/MythoMix-L2-13B-GGML','TheBloke/Nous-Hermes-13B-GGML','TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGML','TheBloke/OpenAssistant-Llama2-13B-Orca-v2-8K-3166-GGML','TheBloke/OpenOrca-Preview1-13B-GGML','TheBloke/OpenOrcaxOpenChat-Preview2-13B-GGML','TheBloke/Platypus2-13B-GGML','TheBloke/Pygmalion-13B-SuperHOT-8K-GGML','TheBloke/Redmond-Puffin-13B-GGML','TheBloke/Robin-13B-v2-SuperHOT-8K-GGML','TheBloke/Samantha-13B-SuperHOT-8K-GGML','TheBloke/Selfee-13B-GGML','TheBloke/Selfee-13B-GGML-DOI','TheBloke/Stable-Platypus2-13B-GGML','TheBloke/StableBeluga-13B-GGML','TheBloke/Vicuna-13B-CoT-GGML','TheBloke/Vicuna-13B-v1.3-German-GGML','TheBloke/Vigogne-2-13B-Instruct-GGML','TheBloke/Vigogne-Instruct-13B-GGML','TheBloke/Wizard-Vicuna-13B-Uncensored-GGML','TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GGML','TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGML','TheBloke/WizardLM-13B-Uncensored-GGML','TheBloke/WizardLM-13B-V1-0-Uncensored-SuperHOT-8K-GGML','TheBloke/WizardLM-13B-V1.0-Uncensored-GGML','TheBloke/WizardLM-13B-V1.1-GGML','TheBloke/WizardLM-13B-V1.2-GGML','TheBloke/WizardMath-13B-V1.0-GGML','TheBloke/airoboros-13B-1.1-GGML','TheBloke/airoboros-13B-gpt4-1.2-GGML','TheBloke/airoboros-13B-gpt4-1.3-GGML','TheBloke/airoboros-13B-gpt4-1.4-GGML','TheBloke/airoboros-13b-gpt4-GGML','TheBloke/airoboros-l2-13B-gpt4-1.4.1-GGML','TheBloke/airoboros-l2-13b-gpt4-2.0-GGML','TheBloke/airoboros-l2-13b-gpt4-m2.0-GGML','TheBloke/based-13b-GGML','TheBloke/chronos-13B-GGML','TheBloke/chronos-wizardlm-uc-scot-st-13B-GGML','TheBloke/gpt4-x-alpaca-13B-GGML','TheBloke/gpt4-x-vicuna-13B-GGML','TheBloke/guanaco-13B-GGML','TheBloke/h2ogpt-4096-llama2-13B-GGML','TheBloke/h2ogpt-4096-llama2-13B-chat-GGML','TheBloke/koala-13B-GGML','TheBloke/llama-2-13B-German-Assistant-v2-GGML','TheBloke/llama-2-13B-Guanaco-QLoRA-GGML','TheBloke/manticore-13b-chat-pyg-GGML','TheBloke/minotaur-13B-GGML','TheBloke/minotaur-13B-fixed-GGML','TheBloke/open-llama-13b-open-instruct-GGML','TheBloke/orca_mini_13B-GGML','TheBloke/orca_mini_v2_13b-GGML','TheBloke/orca_mini_v3_13B-GGML','TheBloke/robin-13B-v2-GGML','TheBloke/samantha-1.1-llama-13B-GGML','TheBloke/samantha-13B-GGML','TheBloke/stable-vicuna-13B-GGML','TheBloke/tulu-13B-GGML','TheBloke/vicuna-13B-v1.5-16K-GGML','TheBloke/vicuna-13B-v1.5-GGML','TheBloke/vicuna-13b-1.1-GGML','TheBloke/vicuna-13b-v1.3.0-GGML','TheBloke/wizard-vicuna-13B-GGML','TheBloke/wizard-vicuna-13B-SuperHOT-8K-GGML','TheBloke/wizardLM-13B-1.0-GGML']{allow-input: true}\n",
        "#@markdown ## If you're stuck for choices, try these:\n",
        "#@markdown * TheBloke/WizardLM-13B-V1.2-GGML\n",
        "#@markdown * TheBloke/WizardLM-13B-V1.1-GGML\n",
        "#@markdown * TheBloke/wizard-vicuna-13B-GGML\n",
        "#@markdown * TheBloke/Llama-2-13B-chat-GGML\n",
        "#@markdown * TheBloke/MythoMax-L2-13B-GGML\n",
        "#@markdown * TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGML\n",
        "#@markdown * TheBloke/Chronos-Beluga-v2-13B-GGML\n",
        "model_file_name =NametoFile[choosed_model_name]\n",
        "model_download_url =download_url(choosed_model_name,model_file_name)\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M $model_download_url -d /content/text-generation-webui/models/ -o $model_file_name"
      ],
      "metadata": {
        "id": "ml40sVBsWerY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d7e286-4b8b-424c-afcc-10dd0d5fd480"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "d67dbd|\u001b[1;32mOK\u001b[0m  |   167MiB/s|/content/text-generation-webui/models//manticore-13b-chat-pyg-superhot-8k.ggmlv3.q5_K_M.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # $\\color{#19ABEA}{\\text{Run the model}}$ { display-mode: \"form\" }\n",
        "# %cd /content/text-generation-webui\n",
        "#@markdown # $\\color{#19ABEA}{\\text{Check ur params and run this cell}}$\n",
        "#@markdown $\\color{#19ABEA}{\\text{Note :}}$ u dont need any of this just uncheck it and run the cell\n",
        "# Api = True #@param {type:\"boolean\"}\n",
        "Public_API = True #@param{type:\"boolean\"}\n",
        "Listen = True #@param{type:\"boolean\"}\n",
        "# @markdown <b>note:</b> public_api include api param\n",
        "#@markdown if the u run choose the Api choice and it doesnt\n",
        "params=\" \"\n",
        "if Public_API :params +=\"--api --public-api \"\n",
        "if Listen :params +=\"--listen \"\n",
        "use_cutom_paramters = False #@param{type:\"boolean\"}\n",
        "custom_parameters=\" \"  #@param {type:\"string\"}\n",
        "if use_cutom_paramters :params +=\" \" + custom_parameters\n",
        "#@markdown <b>note:</b> custom parameter will be added only if u check use_custom_parameters checkbox\n",
        "# !pip install git+https://github.com/mnt4/flask-cloudflared\n",
        "# !pip install flask_cloudflared &\n",
        "!python server.py --share --chat  --n-gpu-layers 200000 --model $model_file_name  $params"
      ],
      "metadata": {
        "id": "jcuuHoRimMyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090fc5d5-2f83-4f88-c1cf-e8980b1c9d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-12 23:23:18 WARNING:\u001b[33mThe gradio \"share link\" feature uses a proprietary executable to create a reverse tunnel. Use it with care.\u001b[0m\n",
            "2023-08-12 23:23:23.055253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-12 23:23:24 INFO:\u001b[32mLoading manticore-13b-chat-pyg-superhot-8k.ggmlv3.q5_K_M.bin...\u001b[0m\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5\n",
            "2023-08-12 23:23:35 INFO:\u001b[32mllama.cpp weights detected: models/manticore-13b-chat-pyg-superhot-8k.ggmlv3.q5_K_M.bin\n",
            "\u001b[0m\n",
            "2023-08-12 23:23:35 INFO:\u001b[32mCache capacity is 0 bytes\u001b[0m\n",
            "llama.cpp: loading model from models/manticore-13b-chat-pyg-superhot-8k.ggmlv3.q5_K_M.bin\n",
            "llama_model_load_internal: format     = ggjt v3 (latest)\n",
            "llama_model_load_internal: n_vocab    = 32000\n",
            "llama_model_load_internal: n_ctx      = 2048\n",
            "llama_model_load_internal: n_embd     = 5120\n",
            "llama_model_load_internal: n_mult     = 256\n",
            "llama_model_load_internal: n_head     = 40\n",
            "llama_model_load_internal: n_head_kv  = 40\n",
            "llama_model_load_internal: n_layer    = 40\n",
            "llama_model_load_internal: n_rot      = 128\n",
            "llama_model_load_internal: n_gqa      = 1\n",
            "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
            "llama_model_load_internal: n_ff       = 13824\n",
            "llama_model_load_internal: freq_base  = 10000.0\n",
            "llama_model_load_internal: freq_scale = 1\n",
            "llama_model_load_internal: ftype      = 17 (mostly Q5_K - Medium)\n",
            "llama_model_load_internal: model size = 13B\n",
            "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
            "llama_model_load_internal: using CUDA for GPU acceleration\n",
            "llama_model_load_internal: mem required  =  601.53 MB (+ 1600.00 MB per state)\n",
            "llama_model_load_internal: allocating batch_size x (640 kB + n_ctx x 160 B) = 480 MB VRAM for the scratch buffer\n",
            "llama_model_load_internal: offloading 40 repeating layers to GPU\n",
            "llama_model_load_internal: offloading non-repeating layers to GPU\n",
            "llama_model_load_internal: offloading v cache to GPU\n",
            "llama_model_load_internal: offloading k cache to GPU\n",
            "llama_model_load_internal: offloaded 43/43 layers to GPU\n",
            "llama_model_load_internal: total VRAM used: 10775 MB\n",
            "llama_new_context_with_model: kv self size  = 1600.00 MB\n",
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n",
            "2023-08-12 23:24:42 INFO:\u001b[32mLoaded the model in 78.12 seconds.\n",
            "\u001b[0m\n",
            "2023-08-12 23:24:42 INFO:\u001b[32mLoading the extension \"gallery\"...\u001b[0m\n",
            " * Downloading cloudflared for Linux x86_64...\n",
            " * Downloading cloudflared for Linux x86_64...\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://8fa2a8e70cef77e868.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "Starting streaming server at public url wss://produce-relocation-allows-rec.trycloudflare.com/api/v1/stream\n",
            "Starting non-streaming server at public url https://ghost-products-boot-ld.trycloudflare.com/api\n",
            "2023-08-12 23:40:30 INFO:\u001b[32mNew character saved to \"characters/TavernAI-Your Oblivious Mother.json\".\u001b[0m\n",
            "2023-08-12 23:41:39 INFO:\u001b[32mSaved /content/text-generation-webui/characters/Naoko.yaml.\u001b[0m\n",
            "2023-08-12 23:41:39 INFO:\u001b[32mSaved characters/Naoko.png.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}